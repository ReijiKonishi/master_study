
@ARTICLE{Park2017-hw,
  title     = "Learning quadratic variance function ({QVF}) {DAG} models via
               overdispersion scoring ({ODS})",
  author    = "Park, Gunwoong and Raskutti, Garvesh",
  abstract  = "Learning DAG or Bayesian network models is an important problem
               in multi-variate causal inference. However, a number of
               challenges arises in learning large-scale DAG models including
               model identifiability and computational complexity since the
               space of directed graphs is huge. In this paper, we address
               these issues in a number of steps for a broad class of DAG
               models where the noise or variance is signal-dependent. Firstly
               we introduce a new class of identifiable DAG models, where each
               node has a distribution where the variance is a quadratic
               function of the mean (QVF DAG models). Our QVF DAG models
               include many interesting classes of distributions such as
               Poisson, Binomial, Geometric, Exponential, Gamma and many other
               distributions in which the noise variance depends on the mean.
               We prove that this class of QVF DAG models is identifiable, and
               introduce a new algorithm, the OverDispersion Scoring (ODS)
               algorithm, for learning large-scale QVF DAG models. Our
               algorithm is based on firstly learning the moralized or
               undirected graphical model representation of the DAG to reduce
               the DAG search-space, and then exploiting the quadratic variance
               property to learn the ordering. We show through theoretical
               results and simulations that our algorithm is statistically
               consistent in the high-dimensional p > n setting provided that
               the degree of the moralized graph is bounded and performs well
               compared to state-of-the-art DAG-learning algorithms. We also
               demonstrate through a real data example involving multi-variate
               count data, that our ODS algorithm is wellsuited to estimating
               DAG models for count data in comparison to other methods used
               for discrete data.",
  journal   = "J. Mach. Learn. Res.",
  publisher = "JMLR.org",
  volume    =  18,
  number    =  1,
  pages     = "8300--8342",
  month     =  jan,
  year      =  2017,
  keywords  = "identifiability, directed acyclic graph, overdispersion,
               multi-variate count distribution, Bayesian networks"
}


@BOOK{Pearl2009-oh,
  title     = "Causality: Models, Reasoning and Inference",
  author    = "Pearl, Judea",
  abstract  = "Written by one of the preeminent researchers in the field, this
               book provides a comprehensive exposition of modern analysis of
               causation. It shows how causality has grown from a nebulous
               concept into a mathematical theory with significant applications
               in the fields of statistics, artificial intelligence, economics,
               philosophy, cognitive science, and the health and social
               sciences. Judea Pearl presents and unifies the probabilistic,
               manipulative, counterfactual, and structural approaches to
               causation and devises simple mathematical tools for studying the
               relationships between causal connections and statistical
               associations. The book will open the way for including causal
               analysis in the standard curricula of statistics, artificial
               intelligence, business, epidemiology, social sciences, and
               economics. Students in these fields will find natural models,
               simple inferential procedures, and precise mathematical
               definitions of causal concepts that traditional texts have
               evaded or made unduly complicated. The first edition of
               Causality has led to a paradigmatic change in the way that
               causality is treated in statistics, philosophy, computer
               science, social science, and economics. Cited in more than 3,000
               scientific publications, it continues to liberate scientists
               from the traditional molds of statistical thinking. In this
               revised edition, Judea Pearl elucidates thorny issues, answers
               readers' questions, and offers a panoramic view of recent
               advances in this field of research. Causality will be of
               interests to students and professionals in a wide variety of
               fields. Anyone who wishes to elucidate meaningful relationships
               from data, predict effects of actions and policies, assess
               explanations of reported events, or form theories of causal
               understanding and causal speech will find this book stimulating
               and invaluable.",
  publisher = "Cambridge University Press",
  edition   = "2nd",
  year      =  2009,
  address   = "USA"
}


@ARTICLE{Park2019-qy,
  title    = "{High-Dimensional} Poisson Structural Equation Model Learning via
              {$\ell_1$-Regularized} Regression",
  author   = "Park, Gunwoong and Park, Sion",
  journal  = "J. Mach. Learn. Res.",
  volume   =  20,
  number   =  95,
  pages    = "1--41",
  year     =  2019
}


% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INCOLLECTION{Park2015-tj,
  title     = "Learning {Large-Scale} Poisson {DAG} Models based on
               {OverDispersion} Scoring",
  booktitle = "Advances in Neural Information Processing Systems 28",
  author    = "Park, Gunwoong and Raskutti, Garvesh",
  editor    = "Cortes, C and Lawrence, N D and Lee, D D and Sugiyama, M and
               Garnett, R",
  abstract  = "In this paper, we address the question of identifiability and
               learning algorithms for large- scale Poisson Directed Acyclic
               Graphical (DAG) models. We define general Poisson DAG models as
               models where each node is a Poisson random variable with rate
               parameter depending on the values of the parents in the
               underlying DAG. First, we prove that Poisson DAG models are
               identifiable from observational data, and present a
               polynomial-time algorithm that learns the Poisson DAG model
               under suitable regularity conditions. The main …",
  publisher = "Curran Associates, Inc.",
  pages     = "631--639",
  year      =  2015
}


% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Shimizu2006-yu,
  title     = "A Linear {Non-Gaussian} Acyclic Model for Causal Discovery",
  author    = "Shimizu, Shohei and Hoyer, Patrik O and Hyv{\"a}rinen, Aapo and
               Kerminen, Antti",
  abstract  = "In recent years, several methods have been proposed for the
               discovery of causal structure from non-experimental data. Such
               methods make various assumptions on the data generating process
               to facilitate its identification from purely observational data.
               Continuing this line of research, we show how to discover the
               complete causal structure of continuous- valued data, under the
               assumptions that (a) the data generating process is linear,(b)
               there are no unobserved confounders, and (c) disturbance
               variables have non-Gaussian …",
  journal   = "J. Mach. Learn. Res.",
  publisher = "jmlr.org",
  volume    =  7,
  number    = "Oct",
  pages     = "2003--2030",
  year      =  2006
}


@BOOK{Spirtes2000-mf,
  title     = "Causation, Prediction, and Search",
  author    = "Spirtes, Peter and Glymour, Clark N and Scheines, Richard and
               Heckerman, David",
  abstract  = "What assumptions and methods allow us to turn observations into
               causal knowledge, and how can even incomplete causal knowledge
               be used in planning and prediction to influence and control our
               environment? In this book Peter Spirtes, Clark Glymour, and
               Richard Scheines address these questions using the formalism of
               Bayes networks, with results that have been applied in diverse
               areas of research in the social, behavioral, and physical
               sciences. The authors show that although experimental and
               observational study designs may not always permit the same
               inferences, they are subject to uniform principles. They
               axiomatize the connection between causal structure and
               probabilistic independence, explore several varieties of causal
               indistinguishability, formulate a theory of manipulation, and
               develop asymptotically reliable procedures for searching over
               equivalence classes of causal models, including models of
               categorical data and structural equation models with and without
               latent variables. The authors show that the relationship between
               causality and probability can also help to clarify such diverse
               topics in statistics as the comparative power of experimentation
               versus observation, Simpson's paradox, errors in regression
               models, retrospective versus prospective sampling, and variable
               selection. The second edition contains a new introduction and an
               extensive survey of advances and applications that have appeared
               since the first edition was published in 1993.",
  publisher = "MIT Press",
  year      =  2000,
  language  = "en"
}
